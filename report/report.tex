\documentclass[11pt,a4paper]{article}

% ─── Packages ──────────────────────────────────────────────────────────────
\usepackage[T1]{fontenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{microtype}

% ─── Theorem environments ──────────────────────────────────────────────────
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}

% ─── Shortcuts ─────────────────────────────────────────────────────────────
\newcommand{\NFA}{\mathrm{NFA}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\DeclareMathOperator*{\argmin}{arg\,min}

% ─── Title ─────────────────────────────────────────────────────────────────
\title{%
  A-Contrario Homography Registration with ORSA:\\
  Implementation, Analysis, and Experiments%
}
\author{
  Clement Marie, Mousshine Rifaki\\
  MVA, ENS Paris-Saclay
}
\date{February 2025\\[0.5em]
\normalsize\url{https://github.com/clmrie/MVA_detection_theory.git}}

% ═══════════════════════════════════════════════════════════════════════════
\begin{document}
\maketitle

\begin{abstract}
We present a complete implementation and experimental analysis of the ORSA
(Optimized Random Sampling) algorithm for automatic homographic registration
of image pairs, following the a-contrario apparatus of Moisan, Moulon, and
Monasse~\cite{moisan2012}. Unlike classical RANSAC, which requires a
manually tuned inlier threshold, ORSA adaptively selects the threshold that
minimizes the Number of False Alarms (NFA), providing rigorous statistical
control on false detections. We describe the detection problem, derive the
NFA formula, verify it satisfies the theoretical requirements, detail our
implementation, and present experiments on real image data covering
null-model validation, robustness to outlier injection, sensitivity
analysis, and failure cases.
\end{abstract}

% ═══════════════════════════════════════════════════════════════════════════
\section{Introduction}\label{sec:intro}

Registering two images of the same scene is a fundamental problem in
computer vision. When the scene is planar or the camera undergoes a pure
rotation, the geometric relationship between the images is described by
a projective homography. Although four correct point correspondences are
sufficient to estimate a homography, feature matching methods such as
SIFT typically produce many outliers, which can severely corrupt a
direct least-squares estimate.

RANSAC addresses this issue by fitting models from random samples and
selecting inliers using a fixed distance threshold. However, this
threshold must be chosen manually and can strongly affect the result.
The a-contrario apparatus provides a principled alternative by selecting
the threshold that minimizes the Number of False Alarms (NFA), thereby
controlling false detections. The ORSA algorithm applies this idea to
homography estimation in a RANSAC-like setting.

In this report, we implement the ORSA algorithm for homographic
registration and evaluate its behavior on real image data.

\subsection{Detection problem}

\subsection{A-contrario viewpoint and Gestalt link}

The a-contrario apparatus draws its motivation from the Helmholtz
principle~\cite{desolneux2000,desolneux2008}: a structure is perceptually
meaningful if it is very unlikely to arise by chance. When a set of point
correspondences all agree with a single homography, this agreement seems
``too organized to be accidental.'' The a-contrario approach makes this
intuition precise. It defines a null model describing random, unstructured
data, and then asks: how surprising would the observed agreement be if the
data were truly random? The Number of False Alarms (NFA) quantifies this
surprise. A detection is declared when $\NFA < 1$, which means the
observed structure would be expected to occur less than once in purely
random data.

\subsection{Contributions}

We implement the full ORSA pipeline following~\cite{moisan2012} and
evaluate it entirely on real image data. On the theoretical side, we
provide a formal proof that the NFA satisfies the a-contrario
guarantee, and we validate this property empirically by running ORSA on
shuffled real SIFT keypoints. On the experimental side, all quantitative
experiments are built around a single real image pair: we test
robustness by injecting random noise correspondences at increasing
ratios, measure sensitivity to the iteration budget and to random seed
choices, and analyze failure cases such as extreme outlier ratios and
scenes with multiple homographies. The implementation handles degeneracy
checks, log-space NFA computation, and iterative refinement with
Levenberg-Marquardt polishing.

% ═══════════════════════════════════════════════════════════════════════════
\section{A-Contrario Model and NFA for Homography}\label{sec:nfa}

\subsection{Background model}\label{sec:background}

\subsection{Symmetric transfer error}\label{sec:residual}

\subsection{Event, precision, and family of tests}

\paragraph{Event.}

\paragraph{Precision parameter.}

\paragraph{Family of tests.}

\paragraph{Number of tests.}

\subsection{NFA formula and log-space computation}

% ═══════════════════════════════════════════════════════════════════════════
\section{Full Derivation: It Is Truly an NFA}\label{sec:verification}

\subsection{Null model}

\subsection{Precise event being tested}

\subsection{Probability bound under the null}

% ═══════════════════════════════════════════════════════════════════════════
\section{The Algorithm}\label{sec:algorithm}

\subsection{ORSA loop}
The ORSA algorithm (\Cref{alg:orsa}) follows the same general strategy
as RANSAC, repeatedly drawing random samples and fitting candidate
models, but replaces the fixed inlier threshold with the a-contrario
NFA criterion. At each iteration, a candidate homography is estimated
from 4 random correspondences, and the NFA is evaluated at every
possible inlier count. The best model across all iterations is the one
that minimizes the NFA.

\begin{algorithm}[htbp]
\caption{ORSA for homography estimation}\label{alg:orsa}
\begin{algorithmic}[1]
\Require $n$ correspondences $(x_i, x'_i)$, image dimensions, max iterations $T$
\Ensure Best homography $H^*$, inlier mask, $\NFA^*$
\State Precompute $\log_{10}\binom{n}{k}$ for $k=0,\ldots,n$ and
       $\log_{10}\binom{m}{4}$ for $m=0,\ldots,n$
\State $\NFA^* \gets +\infty$, $H^* \gets \texttt{None}$
\For{$t = 1, \ldots, T$}
  \State Draw 4 correspondences uniformly at random \label{line:sample}
  \State Check degeneracy (collinearity, conditioning, orientation on sample)
  \If{degenerate} \textbf{continue} \EndIf
  \State Estimate $H$ by DLT with Hartley normalization
  \State Check valid warp (corners map to reasonable locations)
  \State Compute residuals $e_i$ and side indicators $s_i$ for all $n$ matches
  \State Sort residuals: $e_{\sigma(1)} \leq \cdots \leq e_{\sigma(n)}$
  \For{$k = 5, \ldots, n$}
    \State $r_k^2 \gets e_{\sigma(k)}$,\quad
           $\alpha_k \gets \pi\,r_k^2/(w_{s_{\sigma(k)}}h_{s_{\sigma(k)}})$
    \State Compute $\log_{10}\NFA(k)$ via \eqref{eq:lognfa}
  \EndFor
  \State $k^* \gets \argmin_k \NFA(k)$
  \If{$\NFA(k^*) < \NFA^*$}
    \State Update $H^*$, inlier mask, $\NFA^*$
    \State Update adaptive iteration count based on inlier ratio
  \EndIf
\EndFor
\State \textbf{Refinement:} Iteratively refit $H^*$ on inliers (DLT),
       recompute NFA, until convergence
\State \textbf{Polish:} Levenberg-Marquardt optimization on inlier
       correspondences
\State \Return $H^*$, inlier mask, $\NFA^*$
\end{algorithmic}
\end{algorithm}

\subsection{Degeneracy handling}\label{sec:degeneracy}
Not every 4-point sample produces a usable homography. Several checks
are applied to reject degenerate or physically implausible candidates
before they can affect the NFA scoring.

First, we check for collinearity: if any 3 of the 4 sampled points are
nearly collinear (triangle area below a threshold), the sample is
discarded, since the resulting homography would be poorly constrained.
Second, we look at the condition number of the normalized $H$ matrix. A
condition number above~10 indicates numerical instability, so such
candidates are rejected. This check is performed before denormalization
in the DLT, following the IPOL reference~\cite{moisan2012}.

Third, we verify that the homography preserves orientation. Concretely,
we check that $w' = H_{31}x + H_{32}y + H_{33} > 0$ at the sample
points. This is only checked on the 4 sample points, not on all
correspondences, because outlier points may legitimately violate this
condition. Any correspondence where $w' \leq 0$ is assigned infinite
error in the symmetric transfer error computation. Finally, a valid
warp check ensures that the four image corners map to finite, reasonable
locations, with the output-to-input area ratio staying within
$[1/100, 100]$.

\subsection{Refinement}\label{sec:refinement}
The homography returned by the ORSA loop is estimated from only 4
points, so it can usually be improved. We apply two refinement stages.

The first is an iterative DLT refit: we re-estimate the homography
using all current inliers (not just the original 4 sample points),
recompute the residuals and the NFA, and update the inlier set
accordingly. This process is repeated until the NFA no longer improves,
which typically takes 2 to 5 iterations.

The second stage is a Levenberg-Marquardt optimization. Starting from
the refined DLT solution, we minimize the forward transfer error over
the inlier correspondences, treating the 8 independent entries of $H$
as free parameters ($H_{33}$ is fixed to~1). The result is accepted
only if it does not worsen the NFA.

\subsection{Computational complexity}
Each iteration of the main loop performs a fixed-size DLT estimation in
$O(1)$, computes all $n$ residuals in $O(n)$, sorts them in
$O(n \log n)$, and evaluates the NFA for every possible inlier count in
$O(n)$ thanks to the precomputed binomial coefficient tables. The
sorting step dominates, so the cost per iteration is $O(n \log n)$.
Over $T$ iterations, the total complexity is $O(Tn\log n)$. In
practice, the adaptive stopping rule often terminates well before the
maximum number of iterations when the inlier ratio is high, since a
good model is found early.

% ═══════════════════════════════════════════════════════════════════════════
\section{Experiments}\label{sec:experiments}

All experiments are built around the same real image pair (imgB),
which shows two building photographs with a significant perspective
change. SIFT matching produces 1106 correspondences, of which ORSA
identifies 981 inliers (89\%) with $\log_{10}\NFA = -3863$ as the
reference result. Using a single real pair throughout makes the
experimental setup coherent and avoids any artificial bias from
synthetic data generation.

\subsection{Null model validation}\label{sec:exp_null}

A basic sanity check for an a-contrario method is that it should not
produce detections when no meaningful structure is present. We construct
null data by taking the real SIFT keypoints from imgB and randomly
permuting the target points. This breaks all true correspondences while
preserving the spatial clustering of keypoints, which is more realistic
than uniform random sampling.

For each subsample size $n \in \{50, 100, 200, 500, 1000\}$, we run 50
independent trials with different random permutations.

\Cref{tab:null_model} reports the raw $\log_{10}\NFA$ of the best
candidate found in each trial, before clamping non-detections to~0. A
detection would require $\log_{10}\NFA < 0$. No detections occur in any
of the 250 trials; the smallest observed value is $+3.7$ at $n=50$,
still more than three orders of magnitude above the detection threshold.
As $n$ increases, NFA values grow due to the increasing combinatorial
correction.

\begin{table}[htbp]
\centering
\caption{Null model validation using shuffled real SIFT keypoints from
imgB. Values are raw $\log_{10}\NFA$ (before clamping).}
\label{tab:null_model}
\begin{tabular}{@{}lccccc@{}}
\toprule
$n$ (shuffled) & 50 & 100 & 200 & 500 & 1000 \\
\midrule
False alarms / 50 trials & 0 & 0 & 0 & 0 & 0 \\
Mean $\log_{10}\NFA$ & $5.7$ & $7.2$ & $8.7$ & $10.4$ & $12.0$ \\
Min $\log_{10}\NFA$ & $3.7$ & $5.1$ & $6.2$ & $7.3$ & $8.9$ \\
\bottomrule
\end{tabular}
\end{table}

\Cref{fig:null_model} shows the distribution of the best
$\log_{10}\NFA$ values. All observations lie well to the right of the
detection threshold (red dashed line at~0), consistent with the
a-contrario guarantee that false alarms are rare under the null model,
even in the presence of spatially clustered keypoints.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figures/null_model.png}
  \caption{Distribution of best $\log_{10}\NFA$ across 50 trials per
  subsample size on shuffled real SIFT keypoints. The red dashed line
  marks the detection threshold ($\log_{10}\NFA = 0$). All values lie
  well above this threshold, confirming the absence of false alarms.}
  \label{fig:null_model}
\end{figure}

\subsection{Robustness to outlier injection}\label{sec:exp_outlier}

To evaluate robustness to outliers, we start from the 1106 real SIFT
matches of imgB and progressively add random false correspondences,
uniformly distributed in both images.

The ORSA result on the clean data is used as reference: the 981 inliers
found in this setting are treated as ground truth. Precision measures
the fraction of detected inliers that are real matches, while recall
measures the fraction of these reference inliers that are still
recovered after adding noise.

\Cref{tab:synthetic_noise} shows the results averaged over 10 trials per
noise level. ORSA maintains perfect precision and near-perfect recall up
to 71\% injected noise. Even at 83\% noise, detection succeeds in 9 out
of 10 trials, although recall drops to 86\%.


\begin{table}[htbp]
\centering
\caption{Robustness to outlier injection on imgB matches. Precision and
recall are measured against the ORSA reference result on clean data.}
\label{tab:outlier_injection}
\begin{tabular}{@{}lcccccc@{}}
\toprule
Injected noise & 0\% & 18\% & 33\% & 50\% & 71\% & 83\% \\
\midrule
Detection rate & 10/10 & 10/10 & 10/10 & 10/10 & 10/10 & 9/10 \\
Precision & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.90 \\
Recall & 0.99 & 1.00 & 0.98 & 0.98 & 0.98 & 0.86 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/outlier_injection.png}
  \caption{Left: precision and recall vs.\ fraction of injected noise.
  Right: homography consistency (corner error vs.\ reference) vs.\
  noise fraction.}
  \label{fig:outlier_injection}
\end{figure}

\subsection{Real images}\label{sec:exp_real}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.85\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/real_easy_imgA.png}
    \caption{Easy case (imgA): 564/1254 inliers, $\log_{10}\NFA=-1645$.}
  \end{subfigure}
  \\[1em]
  \begin{subfigure}[b]{0.85\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/real_hard_imgB.png}
    \caption{Hard case (imgB): 1023/1212 inliers, $\log_{10}\NFA=-3991$.}
  \end{subfigure}
  \caption{ORSA results on real image pairs. Green lines: inliers; red
  lines: outliers. Top-left: match visualization; top-right: warped blend;
  bottom-left: NFA curve; bottom-right: error histogram.}
  \label{fig:example_matches}
\end{figure}

\paragraph{Easy case (imgA).}
The first image pair shows two bookshelf photographs with a small
viewpoint change. SIFT produces 1254 matches, from which ORSA selects
564 inliers (45\%) with $\log_{10}\NFA = -1645$ and an automatically
chosen threshold of $\varepsilon = 30.3$\,px
(\Cref{fig:example_matches}a). The mean reprojection error is 13.3\,px,
and the computation takes 51\,ms. The very negative NFA indicates a
strong detection. The relatively large threshold reflects the high image
resolution and the fact that the matches are geometrically noisy.

\paragraph{Hard case (imgB).}
The second image pair shows two building photographs with a much larger
perspective change, making the alignment visually more difficult. Out of
1212 SIFT matches, ORSA finds 1023 inliers (84\%) with
$\log_{10}\NFA = -3991$ and a much smaller threshold of
$\varepsilon = 4.1$\,px (\Cref{fig:example_matches}b). The mean
reprojection error is only 1.6\,px, indicating a very accurate
homography. Although the viewpoint change is larger than in imgA, the
matches are more consistent, which explains the tighter threshold and
the higher inlier ratio.


\subsection{Sensitivity analysis}\label{sec:exp_sensitivity}

Both experiments below are run on the 1106 real SIFT matches from imgB.

\paragraph{Iteration budget.}
We vary the maximum number of ORSA iterations to see how many are
actually needed. \Cref{tab:sensitivity_iter} shows that all iteration
budgets from 50 to 5000 yield the same result: 981 inliers,
$\log_{10}\NFA = -3863$, and $\varepsilon = 4.2$\,px. With 89\%
inliers, even 50 iterations are enough to find a good 4-point sample,
and the adaptive stopping rule terminates early in all cases. The
runtime stays around 170\,ms regardless of the budget.

\begin{table}[htbp]
\centering
\caption{Sensitivity to iteration budget (imgB, 1106 matches).}
\label{tab:sensitivity_iter}
\begin{tabular}{@{}lccccc@{}}
\toprule
max\_iter & 50 & 100 & 500 & 1000 & 5000 \\
\midrule
$\log_{10}\NFA$ & $-3863$ & $-3863$ & $-3863$ & $-3863$ & $-3863$ \\
Inliers & 981 & 981 & 981 & 981 & 981 \\
$\varepsilon$ (px) & 4.2 & 4.2 & 4.2 & 4.2 & 4.2 \\
Runtime (ms) & 169 & 166 & 164 & 170 & 167 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Seed stability.}
Since ORSA relies on random sampling, different random seeds could in
principle produce different results. We run 20 trials on the same imgB
matches with different seeds (\Cref{fig:sensitivity}). The
$\log_{10}\NFA$ varies from $-3890$ to $-3596$ (mean $-3859$,
std $61$), and the inlier count varies between 956 and 990 (mean 979,
std 11). This shows that the algorithm is very stable: even though
different seeds lead to different random samples, the final result
barely changes.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/sensitivity.png}
  \caption{Left: inlier count vs.\ max iterations (imgB). Right: NFA
  stability across 20 random seeds.}
  \label{fig:sensitivity}
\end{figure}

\subsection{Failure cases}\label{sec:exp_failure}
Understanding where the algorithm fails is as important as showing where
it succeeds. We test three challenging scenarios.

\paragraph{Shuffled real matches (1000 points).}
We take 1000 real SIFT matches from imgB and randomly shuffle them, so
that all correspondences are wrong but the keypoints remain realistic.
In this case, ORSA finds no homography
($\log_{10}\NFA = 0$), which shows that it does not detect structure when
none exists.

\paragraph{Two homographies in the same data.}
We create a dataset with two different valid homographies (80 matches
each) and add 50 random outliers. Since ORSA is designed to detect only
one homography, it finds the stronger one (76 inliers,
$\log_{10}\NFA = -195$) and ignores the other. Detecting both structures
would require running ORSA multiple times and removing inliers after
each run.

\paragraph{Almost all matches are wrong.}
We mix only 5 correct matches with 300 random ones, so more than 98\% of
the data is noise. In this situation, ORSA almost never samples enough
correct points to estimate a homography and therefore finds no
detections in 20 trials. This is an unavoidable limitation of all
sampling-based methods.


% ═══════════════════════════════════════════════════════════════════════════
\section{Implementation Details}\label{sec:implementation}

The implementation is organized into modular components. NFA computation
(\texttt{src/nfa.py}) is performed entirely in log-space using
precomputed binomial coefficients to ensure numerical stability, and
follows the formula $\binom{n}{k}\binom{k}{4}$ from the original paper.
Homography estimation (\texttt{src/homography.py}) includes DLT with
Hartley normalization, symmetric transfer error, and
Levenberg--Marquardt refinement. Degeneracy checks are implemented in
\texttt{src/degeneracy.py}, and the main ORSA loop with adaptive stopping
and refinement is handled in \texttt{src/orsa.py}. Feature matching
(\texttt{src/matching.py}) supports SIFT and ORB with Lowe’s ratio test.
Experiments and unit tests are provided in \texttt{experiments/} and
\texttt{tests/}, respectively.

\paragraph{Key design decisions.}
Residuals are handled consistently in squared pixel units: since
$\alpha = \pi r^2/(wh)$ and residuals are already squared, the log-space
error term uses a unit multiplier rather than $0.5$. Residuals are
capped at the squared image diagonal to avoid pathological thresholds.
The best model is tracked throughout the ORSA loop, even when
$\NFA \ge 1$, while a detection is declared only if $\NFA < 1$.

\paragraph{Use of AI tools.}
AI tools were used for code organization, debugging, and report
formatting. The algorithmic implementation follows a direct reading of
the IPOL reference~\cite{moisan2012}, with all formulas and proofs
verified manually against the course material.


% ═══════════════════════════════════════════════════════════════════════════
\section{Discussion}\label{sec:discussion}

\subsection{Strengths of the apparatus}

\subsection{Limitations}

\paragraph{Extreme outlier ratios.}
ORSA, like all RANSAC-based methods, relies on randomly drawing a
sample of 4 inliers. When the outlier ratio exceeds roughly 90\%, the
probability of drawing such a clean sample becomes vanishingly small:
with $k$ inliers among $n$ correspondences, this probability is
$\binom{k}{4}/\binom{n}{4}$, which drops off sharply as $k/n$
decreases. Our experiments confirm that detection fails consistently at
98\% outliers (5 inliers among 300).

\paragraph{Single homography model.}
ORSA is designed to find a single homography. When a scene contains
multiple planes (e.g.\ a building with several facades), each plane
defines a different homography, and these structures compete with one
another. As shown in \Cref{sec:exp_failure}, ORSA recovers the
dominant one and treats the rest as outliers. Detecting multiple
homographies would require applying ORSA iteratively, removing detected
inliers between runs.

\paragraph{Very few inliers.}
Even when the outlier ratio is moderate, a small absolute number of
inliers (e.g.\ fewer than 10) makes detection difficult. The
combinatorial terms $\binom{n}{k}\binom{k}{4}$ in the NFA formula grow
rapidly with $n$ and penalize small values of $k$ heavily. In other
words, the NFA is inherently conservative: it requires enough
statistical evidence to overcome the correction for multiple testing.

\subsection{Interpretability and meaning of the NFA value}

\subsection{NFA is a detection criterion, not an accuracy metric}

% ═══════════════════════════════════════════════════════════════════════════
\section{Conclusion}\label{sec:conclusion}

We presented a complete implementation of the ORSA algorithm for
a-contrario homography registration. All experiments are built around
real SIFT matches from a single image pair, avoiding any artificial
bias from synthetic data generation. The null model validation produces
zero false alarms across 250 trials on shuffled real keypoints,
confirming the theoretical guarantee even under realistic spatial
clustering. On the same image pair with up to 83\% injected noise, ORSA
maintains near-perfect precision and recall. The results are stable
across random seeds and iteration budgets. Overall, the a-contrario
apparatus provides a principled, parameter-free alternative to
fixed-threshold RANSAC. The NFA plays a dual role: it serves as the
model selection criterion during the algorithm, and as a measure of how
meaningful the final detection is.

% ═══════════════════════════════════════════════════════════════════════════
\bibliographystyle{plainnat}
\begin{thebibliography}{10}

\bibitem[Moisan et~al.(2012)]{moisan2012}
L.~Moisan, P.~Moulon, and P.~Monasse.
\newblock Automatic homographic registration of a pair of images, with a
  contrario elimination of outliers.
\newblock \emph{Image Processing On Line}, 2:56--73, 2012.

\bibitem[Desolneux et~al.(2000)]{desolneux2000}
A.~Desolneux, L.~Moisan, and J.-M. Morel.
\newblock Meaningful alignments.
\newblock \emph{International Journal of Computer Vision}, 40(1):7--23, 2000.

\bibitem[Desolneux et~al.(2008)]{desolneux2008}
A.~Desolneux, L.~Moisan, and J.-M. Morel.
\newblock \emph{From Gestalt Theory to Image Analysis: A Probabilistic
  Approach}.
\newblock Springer, 2008.

\bibitem[Lowe(2004)]{lowe2004}
D.~G. Lowe.
\newblock Distinctive image features from scale-invariant keypoints.
\newblock \emph{International Journal of Computer Vision}, 60(2):91--110, 2004.

\bibitem[Fischler and Bolles(1981)]{fischler1981}
M.~A. Fischler and R.~C. Bolles.
\newblock Random sample consensus: a paradigm for model fitting with
  applications to image analysis and automated cartography.
\newblock \emph{Communications of the ACM}, 24(6):381--395, 1981.

\bibitem[Hartley and Zisserman(2003)]{hartley2003}
R.~Hartley and A.~Zisserman.
\newblock \emph{Multiple View Geometry in Computer Vision}.
\newblock Cambridge University Press, 2nd edition, 2003.

\bibitem[Chum and Matas(2005)]{chum2005}
O.~Chum and J.~Matas.
\newblock Matching with {PROSAC}: progressive sample consensus.
\newblock In \emph{IEEE CVPR}, pages 220--226, 2005.

\bibitem[Chum et~al.(2003)]{chum2003}
O.~Chum, J.~Matas, and J.~Kittler.
\newblock Locally optimized {RANSAC}.
\newblock In \emph{DAGM}, pages 236--243, 2003.

\end{thebibliography}

\end{document}
